''' 
This script is for benchmarking homodimer proteins. The inputs are chemical shifts, chemical sequence, and AF protein PDB files. From the PDB files will be 
used to generate a NOESY peak list, where all assignments are assumed to be unknown and candidates are determined. From there NOESY peak list can be used
to create restraints and be cycled through PONDEROSA. 

??? Will PONDEROSA generate endurance score
    ?? PONDEROSA will be used to generate monomer 
??? How will I use it in relation to AHNA
    ?? The inputs from PONDEROSA will be used for AHNA
    ?? Inputs are: *.tbl, and finalx.pdb

From the homodimer structure generated by AHNA, an endurance score will be generated and cycled to get best possible structure! 
'''
import os
import numpy as np
import re
import math
from math import sqrt
from itertools import product
import proton_nomenclature 
import PacsyCloseQRef as PACSY
import json
import pynmrstar

############################################################################################################################################################
#                                                                 Parsing Chemical Shifts                                                                  # 
############################################################################################################################################################

def read_pokybuilder_prot(prot_path):
# This function read the *.prot file, which gives the atoms and their chemical shifts existing within the compound. 
# The function returns a list and dictionary of the sequence number, atom name, and chemical shifts.
  f = open(prot_path, 'r')
  lines = f.readlines()
  f.close() 

  # start parsing
  cs_list = []
  cs_dict ={}
  for line in lines:
    sp_list = line.strip().split() #  1 64.2 0.200 CA 1
    try:
      if sp_list[0][0] == '#':
        continue
      cs, atm, nseq = float(sp_list[1]), sp_list[3], int(sp_list[4])
      atm = proton_nomenclature.s32tos12(atm)
      cs_list.append([nseq, atm, cs])
      cs_dict[nseq,atm] = [cs]

    except:
      continue

  return cs_dict, cs_list

# BMRB to prot instead of POKY Builder's
def read_bmrb(fname=None, ename=None):
  try:
    if fname != None:
      strentry = pynmrstar.Entry.from_file(fname)
    elif ename != None:
      strentry = pynmrstar.Entry.from_database(ename)
    else:
      return {}
  except:
    return {}

  # Title
  info_saveframes = strentry.get_saveframes_by_category('entry_information')
  title = info_saveframes[0]['Title'][0].strip()

  # extract sequences
  # sequence list includes a set of lists
    # [nseq, 3-letter-seq, 1-letter-seq]
  sequence_loops = strentry.get_loops_by_category('_Entity_comp_index')
  sequence_dict = json.loads(sequence_loops[0].get_json())
  sequence_list = list(map(lambda x: [x[1], x[2], proton_nomenclature.AAA_dict[x[2]]],
                           sequence_dict['data']))
  fasta = ''.join(list(map(lambda x: x[2], sequence_list)))

  # extract chemical shifts
  atom_chem_shift_loops = strentry.get_loops_by_category('atom_chem_shift')

  # First, try from bond and chemical shift information
  # shift_list includes a set of lists:
  #     [nseq, 3-letter-seq, 1-letter-seq,atom, chemical shift]
  atom_chem_shift_dict = json.loads(atom_chem_shift_loops[0].get_json())
  # print(atom_chem_shift_dict)
  # shift_list = list(map(lambda x: [x[4], x[6], proton_nomenclature.AAA_dict[x[6]], x[7], x[10]],
  #                             atom_chem_shift_dict['data']))
  # shift_list includes a set of lists:
  #     [nseq, atom, chemical shift]
  shift_list = list(map(lambda x: [float(x[4]), x[7], float(x[10])],
                              atom_chem_shift_dict['data']))
 
  return shift_list  # [nseq, atom, chemical shift]

def filter_shift_list(cs_list):
  """Finds identical shifts and modifies the atm name."""
  for i in range(len(cs_list)):
      nseq, atm, shift = cs_list[i]  # Correct way to access elements
      for j in range(i + 1, len(cs_list)):  # Start from i+1 to avoid comparing with itself
          nseq2, atm2, shift2 = cs_list[j]
          if shift == shift2:
              # Modify atm based on the comparison
              match = re.search(r"(\D+)\d+$", atm)
              if match:
                cs_list[i][1] = re.sub(r'\d+$', '*', atm)

              match2 = re.search(r"(\D+)\d+$", atm2)
              if match2:
                cs_list[j][1] = re.sub(r'\d+$', '*', atm2)
  seen = set()
  filtered_cs_list = []
  for sublist in cs_list:
      tuple_sublist = tuple(sublist)  # Convert to tuple
      if tuple_sublist not in seen:
          seen.add(tuple_sublist)
          filtered_cs_list.append(sublist)
  return filtered_cs_list
############################################################################################################################################################
#                                                                 Proton Nomenclature                                                                      # 
############################################################################################################################################################
def protonNomenclatureChange (aa, atom):
  try:
    prot_aa = proton_nomenclature.protonNomenclature[aa] # 'V' -> {'HG':['HG11','HG12','HG13', 'HG21','HG22','HG23']
    nomenclature = prot_aa[atom] # 'HG' -> ['HG11','HG12','HG13', 'HG21','HG22','HG23']
  except:
    return [atom,]
  return nomenclature

############################################################################################################################################################
#                                                              NOESY Simulation: Parsing PDB                                                               #                                                   #
############################################################################################################################################################

def readPDB(pdb_file, modelnumber, nuclei=['H',]):
  """
  Parameters
  ----------
  uploaded_pdb : address to a .pdb file
  modelnumber : the model number in the pdb (starting from 1)
  Returns
  -------
  pdb_list: a list of each [Nseq, atom's coordinates, aa, atom]
  """
  pdbLines, modelList = [], []
  tempLines = open(pdb_file, 'r').readlines()

  # clean
  for line in tempLines:
    #print(line)
    if line[0:4] in ['MODE', 'ATOM', 'ENDM']:
      pdbLines.append(line)

  # fill modelList
  for line in pdbLines:
    if line[0:5] == 'MODEL':
      modelList.append([])
    if line[0:4] != 'ATOM':
      continue
    if line[12:16].strip()[0] not in nuclei:
      continue
    aaa = line[17:20].strip()
    atm = line[12:16].strip()
    nSeq = int(line[23:26].strip()) # <residue sequence>
    x = float(line[30:38].strip())
    y = float(line[38:46].strip())
    z = float(line[46:54].strip())
    c = line[21:22].strip() # <chain_ID>
    # in case MODEL not in PDB.
    if len(modelList) == 0:
      modelList.append([])

    modelList[-1].append( [nSeq, x, y, z, aaa, proton_nomenclature.AAA_dict[aaa], atm, c] )


  return modelList[modelnumber-1]

############################################################################################################################################################
#                                                              NOESY Simulation: Simulate NOESY Peak List                                                  #                                                               
############################################################################################################################################################

def distance3D(atom1, atom2):
  """ takes two coordinates. ex: ((26.266, 25.413, 2.842),
                                  (26.913, 26.639, -3.51))
      returns the distance
  """
  return sqrt((atom1[0] - atom2[0]) ** 2 +
              (atom1[1] - atom2[1]) ** 2 +
              (atom1[2] - atom2[2]) ** 2)

def createDistanceMatrix(pdb_list):
  distMat = np.zeros( (len(pdb_list), len(pdb_list), 4, 4 ) )
  keyList = []
  c_list = 'ABCD'

  for i in range(len(pdb_list)):
    nSeq, x, y, z, aaa, a, atm, c = pdb_list[i]
    keyList.append(c+'_'+a+str(nSeq)+atm)
    for j in range(i+1, len(pdb_list)):
      nSeq2, x2, y2, z2, aaa2, a2, atm2, c2 = pdb_list[j]
      dist = distance3D( (x, y, z), (x2, y2, z2))

      distMat[i, j, c_list.index(c), c_list.index(c2)] = \
        distMat[j, i, c_list.index(c2), c_list.index(c)] = dist
  return distMat, keyList

def get_shift(seqidx, atomname, chem_shifts):
  filterAtoms = list(filter(lambda x :x[0] == seqidx and x[1] ==atomname,
                            chem_shifts))
  if len(filterAtoms) == 0:
    return -9999
  return float(filterAtoms[0][2])

def distance2height(HHdist, offset = 0.0):
    """ distance scaling using r^-6 approximation for H-H """

    min_hh = 1.7  # closest distance between H atoms (1.70 A)
    max_hh = 5.5  # farthest distance observed between H atoms

    max_I = 10**6 # arbitrary value
    min_I = 10**4 # arbitrary value

    approx = -6.0

    dist = min(HHdist, max_hh-offset)
    dist = max(dist, min_hh-offset)

    # A * r**approx + B = I
    # A * min_hh**approx + B = max_I    arbituary max
    # A * max_hh**approx + B = min_I    arbituary min

    # A * (min_hh**approx - max_hh**approx) = max_I - min_I
    #

    A = (max_I - min_I) / ((min_hh-offset)**approx - (max_hh-offset)**approx)       # 75227372.04997641
    B = min_I - A * (max_hh-offset)**approx                     # -19444.257193289242

    #print(A, B, dist, approx, offset)
    return A * dist**approx + B

def parse_key(key):
    c = key.split('_')[0]
    a = key.split('_')[1][0]
    nSeq = int(re.search(regex, key.split('_')[1]).group())
    sep = c+'_'+a+str(nSeq)
    atm = key.split(sep)[1]
    return c, a, nSeq, atm

def create_noesy_peak_list(keyList,noesy_type,chem_shifts,distMat):
  # key: c+'_'+a+str(nSeq)+atm
  # chem_shifts: [nseq, atom, chemical shift]
  c_list = 'ABCD'
  lines = ''
  header = '  %20s    %5s   %5s   %5s   %20s' % ('Assignments','w1','w2','w3', 'Peak Height')
  lines += header + '\n'
  lines += '\n'
  for key in keyList:
    # break down keyList
    c, a, nSeq, atm = parse_key(key)
    atm = proton_nomenclature.s32tos12(a,atm)
    # print(c, a, nSeq, atm)
    # getting heavy atom 'N' or 'C'
    ncatm = proton_nomenclature.protein_attached_heavy_atoms[a][atm]
    if noesy_type == 'nnoe':
      if ncatm[0] != 'N':
        continue
    elif noesy_type == 'cnoe':
      if ncatm[0] != 'C':
        continue

    # get heavy atom shift
    try:
      nc_shift = get_shift(nSeq, ncatm, chem_shifts)
    except:
      continue
    try:
      # get proton atom shift
      h_shift = get_shift(nSeq, atm, chem_shifts)
      # print (h_shift,nSeq, atm)
    except:
      continue
    
    if nc_shift < -1000 or h_shift < -1000:
      continue
    grp1 = f'{a}{nSeq}{ncatm}'
    grp2 = f'{atm}'

    for key2 in keyList:
      c2, a2, nSeq2, atm2 = parse_key(key2)
      dist = distMat[nSeq, nSeq2, c_list.index(c), c_list.index(c2)]
      if key == key2: 
       #avoid sequential data
        continue
      if dist == 0:
        continue
      if dist > 5:
        continue
      try:
        h2_shift = get_shift(nSeq2, atm2, chem_shifts)
      except:
        continue
      if h2_shift < -1000:
        continue

      height = distance2height(dist)
      print (dist)
      if atm == atm2:
        continue
      if nSeq != nSeq2:
        grp3 = f'{a2}{nSeq2}{atm2}'
      else:
        grp3 = f'{atm2}'
      if c != c2:
        grp1, grp2, grp3 = '?','?','?'
      asgn = f'{grp1}-{grp2}-{grp3}'


      line = '  %20s %8.3f %8.3f %8.3f %15d' % (asgn, nc_shift, h_shift,
                                                h2_shift, int(height))
      #print(line)
      lines += line + '\n'
  return lines

############################################################################################################################################################
#                                                             Parse and Filter NOESY Peak Lists                                                            #           
############################################################################################################################################################

def parse_NOESY_list(NOESY_list):
  f = open(NOESY_list, 'r')
  lines = f.readlines()
  f.close()
  nc_shift_list, H_shift_list, h_shift_list = [],[],[]
  peak_height_dict = {}
  for line in lines:
    line = line.strip().split()
    if len(line) < 4:
      continue
    if line[0] == 'Assignments':
      continue
    nc_shift = line[1]
    H_shift = line[2]
    h_shift = line[3]
    peak_height= line[4]
    peak_height_dict[float(H_shift), float(nc_shift), float(h_shift)] = peak_height
    nc_shift_list.append(nc_shift)
    H_shift_list.append(H_shift)
    h_shift_list.append(h_shift)
  # if there's HB21, HB22, and HB23 with similar chemical shifts then they can be read a singular shift rather than three individual shifts (12.2.24)
    # HB21, HB22, and HB23 -> HB2
  return nc_shift_list, H_shift_list, h_shift_list, peak_height_dict
############################################################################################################################################################
#                                                              Finding NOESY Candidates                                                                    #                                                               
############################################################################################################################################################

def read_seq_file(seq_file):
  f = open(seq_file, 'r')
  lines = f.readlines()
  f.close()
  # start parsing
  seq_dict = {}
  for line in lines:
    sp_list = line.strip().split() #  MET 1
    try:
      aaa, nseq = sp_list
      a = proton_nomenclature.AAA_dict[aaa]
      nseq = int(nseq)
      seq_dict[nseq] = [aaa, a]
    except:
      continue

  nstart = min(list(seq_dict.keys()))
  #print (nstart)
  nend = max(list(seq_dict.keys()))

  return seq_dict, nstart, nend # ({1: ['GLY', 'G'],...},1,114)

def matching_seq_atom(cs, cs_list, tol):
  filtered_cs_list = list(filter(lambda x: abs(x[2] - cs) < tol, cs_list))
  seq_atom_list = []
  for nseq, atm, shift in filtered_cs_list:
    seq_atom_list.append([abs(shift-cs), nseq, atm])
  seq_atom_list.sort()
  return seq_atom_list

def matching_bond(cs, cs_list, tol, cs2, cs_list2, tol2):
  filtered_cs_list = list(filter(lambda x: abs(x[2] - cs) < tol, cs_list))
  filtered_cs_list2 = list(filter(lambda x: abs(x[2] - cs2) < tol2, cs_list2))
  seq_atom_list = []

  for nseq, atm, shift in filtered_cs_list:
    for nseq2, atm2, shift2 in filtered_cs_list2:
      if nseq != nseq2:
        continue
      if atm == 'N' or atm == 'C' and atm2 == 'H':
        seq_atom_list.append([sqrt((abs(shift-cs)/tol)**2 + (abs(shift2-cs2)/tol2)**2),
                              nseq, atm, nseq2, atm2])
        continue
      if len(atm) < 2 or len(atm2) < 2:
        continue
      # HB3 -> B3, CB -> B
      if atm2[1:].find(atm[1:]) == 0:
        seq_atom_list.append([sqrt((abs(shift-cs)/tol)**2 + (abs(shift2-cs2)/tol2)**2),
                      nseq, atm, nseq2, atm2])

  seq_atom_list.sort()
  return seq_atom_list
  
############################################################################################################################################################
#                                                              Calculating Distance Probabilities                                                          #
############################################################################################################################################################

def dUPL (CaliConstant, peak_intensity, CaliRatio):
  # dUpl = pow( dCaliConst / dPeakIntensity, 1 / 6.0) * dCaliRatio * 1.5
  distance_candidates = pow((CaliConstant/peak_intensity),1/6.0)*float(CaliRatio)*1.5
  return distance_candidates

def distance_probability (pdbList):
  #obtain x,y,z coordinates from alphafold file
  readPDB_ = readPDB(pdbList,1,nuclei=['H',])
  distMat, keyList = createDistanceMatrix(readPDB_) # wil give distMat and keyList
  for i in range(distMat.shape[0]):
    for j in range(distMat.shape[1]):
      for k in range(distMat.shape[2]):
        for l in range(distMat.shape[3]):
          if k == l and abs(i-j) < 2:
            distMat[i, j, k, l] = 1
            continue
          if k == l:
            distMat[i, j, k, l] = 0
            continue
          if distMat[i, j, k, l] == 0:
            continue
          # if distMat[i,j,k,l] - 6 < 0:
          #   continue
          # this math function calculates the probability of NOESY signal appear, essentially any atoms less than 6A 
          distMat[i, j, k, l] = \
            math.exp((1-max(distMat[i, j, k, l]-6, 0)**1.5)) # the smaller the value, the less likely the signal would appear
  return distMat, keyList

############################################################################################################################################################
#                                                              NOESY Simulation: Write Peak List                                                           # 
############################################################################################################################################################

def aa_array(pdbList):
  # create contact map - indexing
  readPDB_list = readPDB(pdbList, 1, nuclei=['C',])
  aa_matrix = np.zeros((len(pdbList),len(pdbList),4,4)) # for now let's calculate for CA
  for i in range(len(readPDB_list)):
    nSeq, x, y, z, aaa, a, atm, c = readPDB_list[i]
    #print (x,y,z)
    if atm != 'CA':
      continue
    
    for j in range(i+1, len(readPDB_list)):
      nSeq2, x2, y2, z2, aaa2, a2, atm2, c2 = readPDB_list[j]
      if atm2 != 'CA':
        continue
      dist = distance3D( (x, y, z), (x2, y2, z2))
      if dist < 15:
        aa_matrix[nSeq - 1, nSeq2 - 1,0, 1] = \
          aa_matrix[nSeq2 - 1, nSeq - 1, 1, 0] = 1
   # use contact map to filter combination list
   # find any duplicate atom pairs to filter out - so we can just do calculation just once
  return aa_matrix
def aa_dictionary(pdbList):
  readPDB_list = readPDB(pdbList, 1, nuclei = ['H',])
  aa_dict = {}
  for i in range(len(readPDB_list)):
      nSeq, x, y, z, aaa, a, atm, c = readPDB_list[i]
      for j in range(i+1, len(readPDB_list)):
        nSeq2, x2, y2, z2, aaa2, a2, atm2, c2 = readPDB_list[j]
        aa_dict[(atm,nSeq)]=(x, y, z, aaa, a, c)
        if (atm2, nSeq2) not in aa_dict:
          aa_dict[(atm2, nSeq2)] = (x2, y2, z2, aaa2, a2, c2) 
  return aa_dict 
def write_tbl_file(combination, pdbList, aa_dict,seq_dict):
# protons to protons only
# 1 MET    N   2 ASP    H 5.317
# nSeq aaa atom nSeq2 aaa2 atom2 distance
# combination is a tuple
# [HA-H],[H], frq, proton_dist_probability, normailzed frq, Bayes' Theorem, normalized Bayes', endurance score
  proton_matrix = np.zeros((len(pdbList),len(pdbList),4,4)) # (87,87,4,4) for 2N74
  line = ''
  for k in combination:
    # get get attached 'H'and seq_id
    catm, cnSeq = k[0][4], k[0][1]
    # get amino acid
    aa = seq_dict[cnSeq][1]
    # proton nomenclature change 32 to 12
    catm = proton_nomenclature.s32tos12(aa, catm)
    # match = re.search(r"(\D+)\d+$", catm)
    # if match:
    #   catm = re.sub(r'\d+$', "", catm)
    # else:
    #   continue
    # get through space 'H' and seq_id
    catm2,cnSeq2 = k[1][2], k[1][1]
    # get amino acid
    aa2 = seq_dict[cnSeq2][1]
    
    # proton nomenclature change 32 to 12
    catm2 = proton_nomenclature.s32tos12(aa2, catm2)
    # match2 = re.search(r"(\D+)\d+$", catm2)
    # if match2:
    #   catm2 = re.sub(r'\d+$', "", catm2)
    # else:
    #   continue
    try:
      x,y,z = aa_dict[catm, cnSeq][0:3]
    except:
      continue
    try:  
      x2,y2,z2 = aa_dict[catm2,cnSeq2][0:3]
    except:
      continue
    dist = distance3D( (x, y, z), (x2, y2, z2))
    if dist < 1.7:
      continue
    if dist < 5.5:
      proton_matrix[int(cnSeq)-1,int(cnSeq2)-1,0, 1] = \
        proton_matrix[int(cnSeq2)-1,int(cnSeq)-1, 1, 0] = dist
      distRound = round(dist,2)
      dist2 = round(distRound - 1.7,2)
      line += f'assign (segid A and resid {cnSeq} and name {catm}) \
                  (segid B and resid {cnSeq2} and name {catm2}) \
                  {distRound} {dist2} 0.0 \n'  
        
  return line

############################################################################################################################################################
#                                                              NOESY Simulation: Implementation                                                            # 
############################################################################################################################################################
PDB_id = '2N74' 
POKY_job_id = '240926_194514_267'
work_directory = f'/Users/Karen/AHNA/{PDB_id}' # set parent directory
os.system(f"mkdir {work_directory}/Dimer") # to hold NOESY lists and other generate files
# use link to access colab notebook to insert "H" into AlphaFold PDB
link = f'https://colab.research.google.com/drive/1e8FbwUuS1sdFqk5uj5KVkRAOroIqUOQA#scrollTo=j1b-8LoRjF74'

#AlphaFold PDB files with protons added
AF_pdb_filepath = f'{work_directory}/2N74_DeepMind/content/interface' # PDB with protons added
# get chemical shifts
# prot_path =f'{work_directory}/monomer/2n74_cs.prot' # this will be provided by POKY Builder 
# cs_dict, cs_list = read_pokybuilder_prot(prot_path)

# using BMRB data as prot file due to presence of pseudo atom
cs_list = read_bmrb(ename=25793)  # [nseq, atom, chemical shift],
cs_list = filter_shift_list(cs_list) # assign pseudo atoms with *
# print (cs_list)
# get sequence information for homodimers
# fasta file will be provided by user
proton_nomenclature.write_seq_file(work_directory, PDB_id)
seq_path = f'{work_directory}/monomer/{PDB_id}.seq'
seq_dict, nstart, nend = read_seq_file(seq_path)
# get stats file 
stats_file_path = f'{work_directory}/{POKY_job_id}/BestEvaluated/XplorCalc/final_xplor_each_##.pdb.stats'
# NOESY types  
NoesyType = 'cnoe' # or 'nnoe'

regex = r"\d+"
c_list = 'ABCD'
# open AF PDB of protein with the protons added
for PDB in os.listdir(AF_pdb_filepath):
  AF_path = os.path.join(AF_pdb_filepath, PDB)
  if AF_path.endswith('.pdb'):
    AF_readPDB = readPDB(AF_path,1)
    AF_distMat, AF_keyList = createDistanceMatrix(AF_readPDB)
    AF_line = create_noesy_peak_list(AF_keyList, NoesyType, cs_list,AF_distMat)
    # write out NOESY peak list for each AF structure
    AF_PDB_text = open (f'{work_directory}/Dimer/{NoesyType[0].upper()}_NOESY_{PDB[:-4]}.list', 'w')
    AF_PDB_text.write(AF_line)
    AF_PDB_text.close()
# chosen PDB for analysis
pdbList = f'/Users/Karen/AHNA/2N74/2N74_DeepMind/content/interface/fold_2n74_deepmind_model_0_H.pdb'
# distance probability of AF structure
distMat_probability, keyList_probability = distance_probability(pdbList)
# parse chosen NOESY file (written above)
Noesy_file_path = f'{work_directory}/Dimer/{NoesyType[0].upper()}_NOESY_fold_2n74_deepmind_model_0_H.list'
nc_shift, H_shift, h_shift, peak_height_dict = parse_NOESY_list(Noesy_file_path)

# get chemical shifts for N,C,H; all from *.prot file
N_cs_list = list(filter(lambda x: x[1][0] == 'N', cs_list))
C_cs_list = list(filter(lambda x: x[1][0] == 'C', cs_list))
H_cs_list = list(filter(lambda x: x[1][0] == 'H', cs_list))
# NOE tolerances for N,C,H
tol_dict = {'N': 0.35, 'H': 0.03, 'C': 0.4}

tolNC = tol_dict[NoesyType[0].upper()]
tolH = tol_dict['H']

if NoesyType == 'cnoe':
  NC_cs_list = C_cs_list
else:
  NC_cs_list = N_cs_list
ca_contact_matrix = aa_array(pdbList)

content =''
aa_dict = aa_dictionary(pdbList)

for i in range(len(nc_shift)): #nc_shift is ['124.040', '115.257',...] want less than 20,000
  # from noesy peak list
    NC_cs, H_cs, h_cs = nc_shift[i], H_shift[i], h_shift[i]
    bond_matching = matching_bond(float(NC_cs), NC_cs_list, tolNC, float(H_cs), H_cs_list, tolH)
    h_matching_seq = matching_seq_atom(float(h_cs), H_cs_list, tolH)
    combination = product (bond_matching, h_matching_seq)
    combination = list(combination)

    for j, [NH_cand, h_cand] in enumerate(combination):
      # NH_cand: [distance, nseq, 'N', nseq, 'H']
      # h_cand: [distance, nseq, 'H']
      # print (NH_cand,h_cand)
      NH_dist, nseq, NCatom, _, Hatom = NH_cand # distance b/w NH
      h_dist, nseq2, hatom = h_cand # dist b/w NH and h (thru-space)
      # print(ca_contact_matrix[nseq-1][nseq2-1][0][1])
      if ca_contact_matrix[int(nseq)-1][int(nseq2)-1][0][1] != 1:
        continue
      A = seq_dict[nseq][1]
      A2 = seq_dict[nseq2][1]
      frq = PACSY.GetPacsyAbundance(A, Hatom, A2, hatom)
      combination[j] = combination[j] + (frq,)#([1.1644394678885182, 55, 'N', 55, 'H'],
                                              #[0.0009999999999994458, 114, 'H'], 1669)

      Hatom_new = protonNomenclatureChange(A, Hatom)
      hatom_new = protonNomenclatureChange(A2, hatom)
      try:
        Hatom_new = protonNomenclatureChange(A, Hatom)
        if Hatom.endswith('*'):
            Hatom_new = protonNomenclatureChange(A, Hatom[:2]) # assign protons to psuedo atoms HB* --> ['HB2', 'HB3']
      except:
        continue
      try:    
          hatom_new = protonNomenclatureChange(A2, hatom)
          if hatom.endswith('*'):
              hatom_new = protonNomenclatureChange(A, hatom[:2])
      except:
          continue
      proton_dist_probability = 0
      for Hatm in Hatom_new:
        key = f'A_{A}{int(nseq)}{Hatm}'
        try:
          k = keyList_probability.index(key)
        except:
          continue
        for hatm in hatom_new:
          key2 = f'B_{A2}{int(nseq2)}{hatm}'
          try:
            l = keyList_probability.index(key2)
          except:
            continue
          proton_dist_probability = max(proton_dist_probability,
                                        distMat_probability[k,l,0,1])
          if proton_dist_probability == 0:
            continue
      combination[j] = combination[j] + (proton_dist_probability,)

    # filter combination to have all four elements
    combination = list(filter(lambda x: len(x) == 4, combination))
    # get frq values
    freq_list = list(map(lambda x: x[-2], combination))
    # combine frq values
    combined_freq = sum(freq_list)
    if combined_freq == 0:
      continue
    # normalize frq values to 1
    combination = tuple(map(lambda x: x + (x[-2]/combined_freq,), combination)) #0.4422535211267606
    #Bayes' Theorem? Total probability? 
    combination = tuple(map(lambda x: x + (x[-1]*x[-2],), combination))

    #marginal probability and normalize
    prob_list = list(map(lambda x: x[-1], combination)) #[0.4422535211267606, 0.0, 0.0, 0.0]
    combined_prob = sum(prob_list)
    if combined_prob == 0:
      continue
    combination = tuple(map(lambda x:x + (x[-1]/combined_prob,), combination))
    normalized_score = tuple(map(lambda x: x[-1],combination))
    # set endurance score - the final combination is made from the 
    # combination = tuple(map(lambda x: x + (x[-1]*20.0,), combination))
    tbl_line= write_tbl_file(combination, pdbList, aa_dict,seq_dict)
    content += tbl_line
content_list = content.split('\n') # take content lines and turn into list
filter_content = list(set(content_list)) # find duplicate lists and remove them
new_content = '\n'.join(filter_content) # take filtered list and join to strings
print (new_content)
f = open('alt.tbl', 'w')
f.write(new_content)
f.close()  


 



